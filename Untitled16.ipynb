{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openpyxl\n",
        "!pip install --upgrade xlrd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Xihfjq_SHrT",
        "outputId": "a4252bdc-758a-4273-fcba-620a51817ba7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Step 1: Load Training and Testing Data from CSV Files\n",
        "train_df = pd.read_csv('/content/fraudTrain.csv')\n",
        "test_df = pd.read_csv('/content/fraudTest.csv')\n",
        "\n",
        "# Step 2: Data Exploration and Cleaning\n",
        "# Check for missing values\n",
        "print(train_df.isnull().sum())\n",
        "print(test_df.isnull().sum())\n",
        "\n",
        "# Handle missing values (impute with the median for numerical features)\n",
        "# Select numeric columns for imputation\n",
        "numeric_cols_train = train_df.select_dtypes(include=np.number).columns\n",
        "numeric_cols_test = test_df.select_dtypes(include=np.number).columns\n",
        "\n",
        "train_df_numeric = train_df[numeric_cols_train]\n",
        "test_df_numeric = test_df[numeric_cols_test]\n",
        "\n",
        "# Replace infinite values with NaN\n",
        "train_df_numeric.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "test_df_numeric.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Apply imputation only to numeric columns\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "train_df_imputed_numeric = pd.DataFrame(imputer.fit_transform(train_df_numeric), columns=train_df_numeric.columns)\n",
        "test_df_imputed_numeric = pd.DataFrame(imputer.transform(test_df_numeric), columns=test_df_numeric.columns)\n",
        "\n",
        "# Concatenate imputed numeric columns back with original DataFrame\n",
        "train_df_imputed = pd.concat([train_df_imputed_numeric, train_df.drop(columns=numeric_cols_train, errors='ignore')], axis=1)\n",
        "test_df_imputed = pd.concat([test_df_imputed_numeric, test_df.drop(columns=numeric_cols_test, errors='ignore')], axis=1)\n",
        "\n",
        "# Step 3: Feature Engineering\n",
        "# Split the data into features (X) and target (y)\n",
        "X_train = train_df_imputed.drop('is_fraud', axis=1)  # Assuming 'is_fraud' is the target column\n",
        "y_train = train_df_imputed['is_fraud']\n",
        "\n",
        "X_test = test_df_imputed.drop('is_fraud', axis=1)\n",
        "y_test = test_df_imputed['is_fraud']\n",
        "\n",
        "# Drop non-numeric columns from X_train and X_test\n",
        "X_train = X_train.select_dtypes(include=np.number)\n",
        "X_test = X_test.select_dtypes(include=np.number)\n",
        "\n",
        "# Step 4: Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 5: Train Models\n",
        "\n",
        "# Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"\\nRandom Forest Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# Logistic Regression\n",
        "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test_scaled)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report(y_test, y_pred_lr))\n",
        "\n",
        "# Decision Tree\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train_scaled, y_train)\n",
        "y_pred_dt = dt_model.predict(X_test_scaled)  # Get predictions for Decision Tree\n",
        "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
        "print(\"\\nDecision Tree Classification Report:\\n\", classification_report(y_test, y_pred_dt))"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94_ieBW-Yx0x",
        "outputId": "0bc98522-49eb-49f0-cec2-3c26f53941ae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unnamed: 0               0\n",
            "trans_date_trans_time    0\n",
            "cc_num                   1\n",
            "merchant                 1\n",
            "category                 1\n",
            "amt                      1\n",
            "first                    1\n",
            "last                     1\n",
            "gender                   1\n",
            "street                   1\n",
            "city                     1\n",
            "state                    1\n",
            "zip                      1\n",
            "lat                      1\n",
            "long                     1\n",
            "city_pop                 1\n",
            "job                      1\n",
            "dob                      1\n",
            "trans_num                1\n",
            "unix_time                1\n",
            "merch_lat                1\n",
            "merch_long               1\n",
            "is_fraud                 1\n",
            "dtype: int64\n",
            "Unnamed: 0               0\n",
            "trans_date_trans_time    0\n",
            "cc_num                   0\n",
            "merchant                 0\n",
            "category                 0\n",
            "amt                      0\n",
            "first                    0\n",
            "last                     0\n",
            "gender                   0\n",
            "street                   0\n",
            "city                     0\n",
            "state                    0\n",
            "zip                      0\n",
            "lat                      0\n",
            "long                     0\n",
            "city_pop                 0\n",
            "job                      0\n",
            "dob                      0\n",
            "trans_num                0\n",
            "unix_time                0\n",
            "merch_lat                0\n",
            "merch_long               0\n",
            "is_fraud                 0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-05ea8c2cf9d6>:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df_numeric.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
            "<ipython-input-16-05ea8c2cf9d6>:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_df_numeric.replace([np.inf, -np.inf], np.nan, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.9960447636305398\n",
            "\n",
            "Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00    553574\n",
            "         1.0       0.39      0.05      0.08      2145\n",
            "\n",
            "    accuracy                           1.00    555719\n",
            "   macro avg       0.69      0.52      0.54    555719\n",
            "weighted avg       0.99      1.00      0.99    555719\n",
            "\n",
            "Logistic Regression Accuracy: 0.9955211176871764\n",
            "\n",
            "Logistic Regression Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00    553574\n",
            "         1.0       0.00      0.00      0.00      2145\n",
            "\n",
            "    accuracy                           1.00    555719\n",
            "   macro avg       0.50      0.50      0.50    555719\n",
            "weighted avg       0.99      1.00      0.99    555719\n",
            "\n",
            "Decision Tree Accuracy: 0.8983515049872327\n",
            "\n",
            "Decision Tree Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.90      0.95    553574\n",
            "         1.0       0.01      0.33      0.02      2145\n",
            "\n",
            "    accuracy                           0.90    555719\n",
            "   macro avg       0.51      0.62      0.49    555719\n",
            "weighted avg       0.99      0.90      0.94    555719\n",
            "\n"
          ]
        }
      ]
    }
  ]
}